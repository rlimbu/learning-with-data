{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello scikit-learn!\n",
    "\n",
    "In the hallowed tradition started by K & R in their book *The C Programming Language*, what follows is a \"Hello World\" program for [scikit-learn](http://scikit-learn.org/stable/), the well-known machine learning package for Python.\n",
    "\n",
    "One of the strengths of the scikit-learn package is the consistent interface that it provides to users. The steps in using a model in scikit-learn are as follows:\n",
    "\n",
    "1. Import the class to use\n",
    "2. Instantiate the class, optionally tuning hyperparameters\n",
    "3. Fit the model using training dataset\n",
    "4. Make predictions using the fitted model\n",
    "\n",
    "In return for providing this consistent interface, scikit-learn expects the followings:\n",
    "\n",
    "1. Separate objects for features and responses\n",
    "2. Numeric objects for features and responses\n",
    "3. Features and responses in [NumPy](http://www.numpy.org/) arrays\n",
    "4. Specific shapes for features and responses\n",
    "\n",
    "Time to see all this in action using the famous [iris flower dataset](http://www.numpy.org/), which is included in the scikit-learn package. Features in the dataset will be used to train a k-nearest neighbour classifier model from the scikit-learn library. Then, the model will be used to predict the species of previously unseen iris flowers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the method to load iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load the iris data into a variable named iris\n",
    "iris = load_iris()\n",
    "\n",
    "# check the type of iris. Turns out scikit-learn saves iris dataset in a container\n",
    "# type called \"Bunch\"\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and feature names are in the attributes *data* and *feature_names*. Similarly, target and target names are  are in the attributes *target* and *target_names*. Let's explore these and other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# print the feature names\n",
    "print(iris.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n"
     ]
    }
   ],
   "source": [
    "# print the first 5 lines of the features\n",
    "print(iris.data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "# print the five last lines of the features\n",
    "print(iris.data[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the features, i.e. number of rows and columns\n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-136-d4cc81668bc8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-136-d4cc81668bc8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    The above output shows that there are 150 samples of iris flowers comprising 4 features\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The above output shows that there are 150 samples of iris flowers comprising 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, let's check the data type of the features. \n",
    "# scikit-learn expects features to be in NumPy arrays\n",
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# let's do the same for the targets, starting with target name\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 5 targets\n",
    "print(iris.target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The targets, which are species of the iris flower, are encoded as integers. The first 5 samples belong to the same species *setosa*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# print the last 5 targets\n",
    "print (iris.target[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the target dataset\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that there are 150 records of target consisting of 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# check the data type of target. scikit-learn expects NumPy arras\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to split the iris dataset into training and test datasets. The rule of thumb for this split is 80/20 - splitting 80% of the dataset into training and the remaining into test dataset.\n",
    "\n",
    "It is easy enough to slice the iris dataset into training and test datasets, but scikit-learn provides a function, *train_test_split()*, for this purpose. Among other things, this function has an argument for the split size. As the datasets are randomly split into training and test datasets, the function provides an argument, *random state*, that can be set to reproduce the split later.\n",
    "\n",
    "The following code performs 70/30 split of the iris dataset into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import train_test_split() \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 45 105 45\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the iris dataset has been split into training and test sets, it is time to perform the four steps involved in using scikit-learn models as mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import k-nearest neighbour classifer, instantiate it with the number of neighbors to 6 - this is\n",
    "# an example of hyerparameter tuning - fit the model with the training dataset, and then use the model to predict\n",
    "# the species of the iris flowers in the test dataset\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted values for the iris flowers in the test dataset are saved in the variable *y_pred*. How accurately did the knn classifier predict the species of the test dataset? To answer this question, scikit-learn provides some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accurately predicted the species of the 98% of the test dataset. Not bad for a simple model like knn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
